{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT3182 - Big data management and processing\n",
    "\n",
    "Name: Cheong Karr Kei\n",
    "\n",
    "Student ID: 30091497\n",
    "\n",
    "Email: kche0070@student.monash.edu\n",
    "\n",
    "\n",
    "# Assignment Part B #\n",
    "\n",
    "**Task 1. Processing Stream Data**\n",
    "\n",
    "**Streaming application**\n",
    "\n",
    "In this notebook, we have the streaming application which has a local streaming context with two execution threads and a batch interval of 10 seconds. This streaming application receives data from all of our three producers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.3.0 pyspark-shell'\n",
    "\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pygeohash as pgh\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "\n",
    "def compare_location(location1, location2, precision):\n",
    "    \"\"\"\n",
    "    This function takes in two locations and uses the geo-hashing algorithm to tell us if they are close to each other\n",
    "\n",
    "    Params: \n",
    "    1. location1: tuple of (latitude, longitude)\n",
    "    1. location2: tuple of (latitude, longitude)\n",
    "    3. precision: integer indicating the precision of the geo-hashing algorithm\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    #boolean which tells us whether the two locations are close to each other \n",
    "    close = False\n",
    "\n",
    "    hash_1 = pgh.encode(location1[0], location1[1], precision)\n",
    "    hash_2 = pgh.encode(location2[0], location2[1], precision)\n",
    "\n",
    "    if hash_1 == hash_2:\n",
    "        close = True\n",
    "        \n",
    "    return close\n",
    "\n",
    "def geo_hash(location, precision):\n",
    "    hash_1 = pgh.encode(location[0], location[1], precision)\n",
    "    \n",
    "    return hash_1\n",
    "\n",
    "\n",
    "\n",
    "def sendDataToDB(iter):\n",
    "    client = MongoClient()\n",
    "    #Create DB\n",
    "    db = client.fit3182_assignment_db\n",
    "    #Create climates collection\n",
    "    #partb_climate = db.climate_stream\n",
    "    partb_climate = db.climate_stream_test\n",
    "    #Create fires collection\n",
    "    #partb_fire = db.fire_stream\n",
    "    partb_fire = db.fire_stream_test\n",
    "    \n",
    "    #array to store climate data \n",
    "    climate_data = []\n",
    "    #array to store AQUA fire data \n",
    "    aqua_data = []\n",
    "    #array to store TERRA fire data \n",
    "    terra_data = []\n",
    "    \n",
    "    for record in iter:\n",
    "        #get key\n",
    "        key = record[0]\n",
    "        #get document\n",
    "        data = json.loads(record[1])\n",
    "        \n",
    "        #append data to the arrays according to the key \n",
    "        #if it is climate data\n",
    "        if key == \"P1\":\n",
    "            climate_data.append(data)\n",
    "            \n",
    "\n",
    "        #if it is AQUA fire data\n",
    "        if key == \"P2\":\n",
    "            aqua_data.append(data)\n",
    "\n",
    "        #if it is TERRA fire data\n",
    "        if key == \"P3\":\n",
    "            terra_data.append(data)\n",
    "    \n",
    "         \n",
    "    print(\"Climate data: \" + str(len(climate_data)))\n",
    "    print(\"AQUA data: \" + str(len(aqua_data)))\n",
    "    print(\"TERRA data: \" + str(len(terra_data)))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    #variable to store the final climate data that we will add to the database \n",
    "    final_climate = None\n",
    "    #array to store the final fire data that we will add to the database \n",
    "    final_fires = []\n",
    "    #array to store the fire data that are close to the climate location \n",
    "    close_fires = []\n",
    "    \n",
    "    \n",
    "    #proceed to data processing only if there is climate data \n",
    "    if len(climate_data)!= 0:\n",
    "        #if there is no hotspot data, just store the climate data \n",
    "        if len(aqua_data) == 0 and len(terra_data) == 0:\n",
    "            final_climate = climate_data[0]\n",
    "            final_climate[\"fires\"] = []\n",
    "        \n",
    "        #if there is hotspot data, compare these hotspot data locations with our climate data location\n",
    "        else:\n",
    "            #obtain climate data \n",
    "            data = climate_data[0]\n",
    "            #obtain the latitude of climate data\n",
    "            climate_lat = data[\"latitude\"]\n",
    "            #obtain the longitude of climate data\n",
    "            climate_lon = data[\"longitude\"] \n",
    "            #save latitude and longitude of climate data as  tuple\n",
    "            climate_loc = (climate_lat, climate_lon)\n",
    "            \n",
    "            #if there is AQUA data\n",
    "            if len(aqua_data) > 0:\n",
    "                #iterate each data\n",
    "                for data in aqua_data:\n",
    "                    #obtain the latitude of AQUA data\n",
    "                    aqua_lat = data[\"latitude\"]\n",
    "                    #obtain the longitude of AQUA data\n",
    "                    aqua_lon = data[\"longitude\"]\n",
    "                    #save latitude and longitude of AQUA data as  tuple\n",
    "                    aqua_loc = (aqua_lat, aqua_lon)\n",
    "                    #compare the locations using geo-hashing algorithm with precision 3 \n",
    "                    close = compare_location(climate_loc, aqua_loc, 3)\n",
    "                    #if they are close, add AQUA data to array of close locations \n",
    "                    print(close)\n",
    "                    if close:\n",
    "                        close_fires.append(data)\n",
    "                        pprint(data)\n",
    "            \n",
    "            #if there is TERRA data\n",
    "            if len(terra_data) > 0:\n",
    "                #iterate each data\n",
    "                for data in terra_data:\n",
    "                    #obtain the latitude of TERRA data\n",
    "                    terra_lat = data[\"latitude\"]\n",
    "                    #obtain the longitude of TERRA data\n",
    "                    terra_lon = data[\"longitude\"]\n",
    "                    #save latitude and longitude of TERRA data as  tuple\n",
    "                    terra_loc = (terra_lat, terra_lon)\n",
    "                    #compare the locations using geo-hashing algorithm with precision 3 \n",
    "                    close = compare_location(climate_loc, terra_loc, 3)\n",
    "                    #if they are close, add TERRA data to array of close locations \n",
    "                    print(close)\n",
    "                    if close:\n",
    "                        close_fires.append(data)\n",
    "                        pprint(data)\n",
    "                        \n",
    "            \n",
    "        #if there are no close fires to climate data, just add climate data \n",
    "        if len(close_fires) == 0:\n",
    "            final_climate = climate_data[0]\n",
    "            final_climate[\"fires\"] = []\n",
    "            \n",
    "        #if there are close fires to climate data, perform geo-hashing algorithm and group the fire data by that value\n",
    "        else:\n",
    "            #initialise dictionary to store fire data \n",
    "            fire_hash = {}\n",
    "            \n",
    "            #iterate close fire data\n",
    "            for data in close_fires:\n",
    "                #get latitude of fire data \n",
    "                fire_lat = data[\"latitude\"]\n",
    "                #get longitude of fire data \n",
    "                fire_lon = data[\"longitude\"]\n",
    "                #store location as tuple\n",
    "                fire_loc = (fire_lat, fire_lon)\n",
    "                #get geo hash of location with precision 5\n",
    "                current_hash = geo_hash(fire_loc, 5)\n",
    "                \n",
    "                #if geo hash of current location already exists, append to existing array\n",
    "                if current_hash in fire_hash.keys():\n",
    "                    fire_hash[current_hash].append(data)\n",
    "                #else, add the key and array value\n",
    "                else:\n",
    "                    fire_hash[current_hash] = [data]\n",
    "                    \n",
    "            #iterature through the dictionary\n",
    "            for key in fire_hash:\n",
    "                #if there is only one data for that key, add to final fires data straight away \n",
    "                if len(fire_hash[key]) == 1:\n",
    "                \n",
    "                    #add to final fire data\n",
    "                    final_fires.append(fire_hash[key][0])\n",
    "                \n",
    "                #if there is more than one data for that key, obtain the average latitude, longitude, confidence and surface temperature\n",
    "                elif len(fire_hash[key]) > 1:\n",
    "                    \n",
    "                    #store total latitude \n",
    "                    total_lat = None\n",
    "                    #store total longitude \n",
    "                    total_lon = None\n",
    "                    #store total confidence\n",
    "                    total_conf = None\n",
    "                    #store total surface temperature\n",
    "                    total_temp = None\n",
    "                    \n",
    "                    #iterate through data with same key\n",
    "                    for data in fire_hash[key]:\n",
    "                        #get latitude\n",
    "                        lat = data[\"latitude\"]\n",
    "                        #get longitude\n",
    "                        long = data[\"longitude\"]\n",
    "                        #get confidence\n",
    "                        conf = data[\"confidence\"]\n",
    "                        #get surface temperature\n",
    "                        temp = data[\"surface_temperature_celcius\"]\n",
    "                        \n",
    "                        #obtain total latitude\n",
    "                        if total_lat == None:\n",
    "                            total_lat = lat \n",
    "                        else: \n",
    "                            total_lat += lat \n",
    "                        #obtain total longitude\n",
    "                        if total_lon == None:\n",
    "                            total_lon = long\n",
    "                        else: \n",
    "                            total_lon += long \n",
    "                        #obtain total confidence\n",
    "                        if total_conf == None:\n",
    "                            total_conf = conf \n",
    "                        else: \n",
    "                            total_conf += conf\n",
    "                        #obtain total surface temperature\n",
    "                        if total_temp == None:\n",
    "                            total_temp = temp \n",
    "                        else: \n",
    "                            total_temp += temp \n",
    "                            \n",
    "                    \n",
    "                    #obtain average \n",
    "                    total_data = len(fire_hash[key])\n",
    "                    #store new latitude \n",
    "                    new_lat = round(total_lat/total_data, 3)\n",
    "                    #store new longitude \n",
    "                    new_lon = round(total_lon/total_data,3)\n",
    "                    #store new confidence\n",
    "                    new_conf = round(total_conf/total_data)\n",
    "                    #store new surface temperature\n",
    "                    new_temp = round(total_temp/total_data)\n",
    "                    #store new datetime, in this case we just use the datetime of last element in array\n",
    "                    new_datetime = fire_hash[key][len(fire_hash[key])-1][\"datetime\"]\n",
    "                    \n",
    "                    #create new data \n",
    "                    new_fire = {\n",
    "                        \"latitude\": float(new_lat),\n",
    "                        \"longitude\": float(new_lon),\n",
    "                        \"confidence\": int(new_conf),\n",
    "                        \"surface_temperature_celcius\": int(new_temp),\n",
    "                        \"datetime\": new_datetime\n",
    "                    }\n",
    "                    \n",
    "                    #add data to final fires data\n",
    "                    final_fires.append(new_fire)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "        #get climate data \n",
    "        final_climate = climate_data[0]\n",
    "\n",
    "        #get the date\n",
    "        climate_date = final_climate[\"date\"]\n",
    "\n",
    "        #get the air temperature \n",
    "        air_temp = final_climate[\"air_temperature_celcius\"]\n",
    "        #get the GHI\n",
    "        ghi = final_climate[\"GHI_w/m2\"]\n",
    "        #store the cause of fire as other by default\n",
    "        fire_cause = \"other\"\n",
    "\n",
    "        #if air temperature >20 and GHI > 180, cause of fire is \"natural\"\n",
    "        if air_temp > 20 and ghi > 180:\n",
    "            fire_cause = \"natural\"               \n",
    "\n",
    "        #if we still have fire data to add \n",
    "        if len(final_fires) >0:\n",
    "            #iterate through fire data\n",
    "            for data in final_fires:\n",
    "                fire_dt = data[\"datetime\"]\n",
    "                #get time \n",
    "                fire_dt = dt.datetime.strptime(fire_dt,\"%Y-%m-%dT%H:%M:%S\").strftime(\"%X\")\n",
    "                #change format of climate date\n",
    "                climate_date_formatted = dt.datetime.strptime(climate_date, \"%d/%m/%Y\").strftime(\"%Y-%m-%d\")\n",
    "                #new datetime for fire data \n",
    "                new_dt = climate_date_formatted + \"T\" + fire_dt\n",
    "                #change datetime\n",
    "                data[\"datetime\"] = new_dt\n",
    "                #add cause of fire \n",
    "                data[\"cause\"] = fire_cause\n",
    "                #add date\n",
    "                data[\"date\"] = climate_date\n",
    "                \n",
    "            \n",
    "            \n",
    "            #insert fire data to database \n",
    "            partb_fire.insert_many(final_fires)\n",
    "            \n",
    "            \n",
    "            #get the ID's of inserted fire data \n",
    "            fire_ids = []\n",
    "            \n",
    "            results = partb_fire.find({\"date\":climate_date})\n",
    "            for doc in results:\n",
    "                fire_ids.append(doc[\"_id\"])\n",
    "                \n",
    "            \n",
    "            #add fires field to climate data containing the ID's of corresponding fires\n",
    "            final_climate[\"fires\"] = fire_ids\n",
    "            \n",
    "        #add climate data to database \n",
    "        partb_climate.insert_one(final_climate)\n",
    "        \n",
    "    \n",
    "    print(\"Climate data:\")\n",
    "    pprint(final_climate)\n",
    "    print(\"Fire data:\")\n",
    "    for i in final_fires:\n",
    "        pprint(i)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "       \n",
    "   \n",
    "        \n",
    "    client.close()\n",
    "\n",
    "n_secs = 10\n",
    "topic = \"FIT3182_Assignment\"\n",
    "\n",
    "conf = SparkConf().setAppName(\"KafkaStreamProcessor\").setMaster(\"local[2]\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, n_secs)\n",
    "    \n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "                        'bootstrap.servers':'127.0.0.1:9092', \n",
    "                        'group.id':'fit3182-group', \n",
    "                        'fetch.message.max.bytes':'15728640',\n",
    "                        'auto.offset.reset':'largest'})\n",
    "                        # Group ID is completely arbitrary\n",
    "\n",
    "lines = kafkaStream.foreachRDD(lambda rdd: rdd.foreachPartition(sendDataToDB))\n",
    "\n",
    "ssc.start()\n",
    "#time.sleep(600) # Run stream for 10 minutes just in case no detection of producer\n",
    "ssc.awaitTermination()\n",
    "ssc.stop(stopSparkContext=True,stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymongo import MongoClient\n",
    "# from pprint import pprint\n",
    "# client = MongoClient()\n",
    "# #Create DB\n",
    "# db = client.fit3182_assignment_db\n",
    "# #Create climates collection\n",
    "# partb_climate = db.partb_climate\n",
    "# #Create fires collection\n",
    "# partb_fire = db.partb_fire\n",
    "\n",
    "# partb_climate.drop()\n",
    "# partb_fire.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
